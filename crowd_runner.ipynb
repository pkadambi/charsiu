{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a490935-7230-4e3f-bcde-7ff60d07276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics_core.audio import Audio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from IPython.display import Audio as Aud\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e8ae3e-6a3d-4eda-b07e-bf351c91ea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prad.kadambi/anaconda3/envs/pykaldi/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (5,50,51,52,53,54,55,56,57,58,59,60,62,63,64,65,66,67,68,69,73,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,150,151,152,153,154,155,156,157,169,170,171,172,173,174,335,336,338,339,340,341,342,343,344,345,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,371,372,373,374,375,376,377,378,379,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,450,451,452,453,454,455,456,457,458,459,460,461,462,463,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,486,579) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/dataset_files/crowd-source__asr_2021-11-08__final__ALL.csv')\n",
    "dnndf = pd.read_csv('./data/dataset_files/DNN.csv')\n",
    "crowd_df = df[df['steps.stepCategory']=='sentence']\n",
    "dnncrowd = dnndf[dnndf['sample'].isin(['crowd', 'crowd_issue'])]\n",
    "dnnids = list(dnncrowd['File_id'])\n",
    "crowd_df = crowd_df[crowd_df['steps.participantId'].isin(dnnids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96489fec-7e90-4fdf-9c2e-9ce00c391c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_to_npscale(bucket, obj_key):\n",
    "    data = Audio.from_wav_s3_bucket(bucket=bucket, object_key=obj_key)\n",
    "    return data.audio_signal / (2 ** 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ce19d1-3408-4adc-9a71-888ea9639469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session.appDevice', 'session.appName', 'session.appPlatform',\n",
       "       'session.appVersion', 'session.createdTime', 'session.inClinic',\n",
       "       'session.language', 'session.microphone', 'session.participantId',\n",
       "       'session.partitionId', 'session.sessionCount', 'session.sessionId',\n",
       "       'session.sessionScriptId', 'session.sortId', 'session.startTime',\n",
       "       'session.totalSteps', 'session.type', 'session.uuid',\n",
       "       'steps.partitionId', 'steps.sortId', 'steps.type',\n",
       "       'steps.participantId', 'steps.sessionId', 'steps.stepId',\n",
       "       'steps.createdTime', 'steps.s3Bucket', 'steps.s3Path',\n",
       "       'steps.elicitType', 'steps.microphone', 'steps.stepCategory',\n",
       "       'steps.startTime', 'steps.endTime', 'steps.status', 'steps.name',\n",
       "       'steps.sequenceNumber', 'steps.rating', 'steps.singleSelect',\n",
       "       'steps.uuid', 'steps.promptListSize', 'steps.promptType',\n",
       "       'steps.prompt', 'steps.originalSampleRate', 'steps.stepData',\n",
       "       'transcript.simple.human', 'transcript.raw.human',\n",
       "       'transcript.createdTime.human', 'transcript.stepId',\n",
       "       'transcript.raw.aws', 'transcript.simple.aws',\n",
       "       'transcript.createdTime.aws'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_df.columns[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc6c3508-651f-45a5-af5c-dd2ec155704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stepid_to_transcript = \\\n",
    "# {'supermarket': 'The supermarket chain shut down because of poor management', \n",
    "# 'money': 'Much more money must be donated to make this department succeed', \n",
    "# 'coffee': 'In this famous coffee shop they serve the best donuts in town',\n",
    "# : 'The chairman decided to pave over the shopping center garden', \n",
    "# 33: 'The standards committee met this afternoon in an open meeting'}\n",
    "prompt_substrings = ['supermarket chain', 'more money', 'famous coffee', 'chairman decided', 'standards committee']\n",
    "substr_to_transcript = {'supermarket chain': 'The supermarket chain shut down because of poor management', \n",
    "'more money': 'Much more money must be donated to make this department succeed', \n",
    "'famous coffee': 'In this famous coffee shop they serve the best donuts in town',\n",
    "'chairman decided' : 'The chairman decided to pave over the shopping center garden', \n",
    "'standards committee': 'The standards committee met this afternoon in an open meeting'}\n",
    "\n",
    "steps = list(stepid_to_transcript.keys())\n",
    "\n",
    "# nans = 0\n",
    "# for pid in participant_ids:\n",
    "#     dct = {}\n",
    "#     for _prompt_substr in prompt_substrings:\n",
    "#         stepval = int(get_stepid_from_prompt(crowd_df, participant_id=pid, prompt=_prompt_substr))\n",
    "#         dct[_prompt_substr] = stepval\n",
    "#     if np.mean(list(dct.values()))==-1:\n",
    "#         nans+=1\n",
    "#     print(dct)\n",
    "# print(nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a9f3896-6bb2-45b6-bfc1-1689676ead3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            steps.prompt  steps.stepId\n",
      "90246  The supermarket chain shut down because of poo...          29.0\n",
      "90247  Much more money must be donated to make this d...          30.0\n",
      "90248  In this famous coffee shop, they serve the bes...          31.0\n",
      "90249  The chairman decided to pave over the shopping...          32.0\n",
      "90250  The standards committee met this afternoon in ...          33.0\n",
      "90251          His father raised a local breed of sheep.          34.0\n",
      "90252  The play park is roughly to the east of the sc...          35.0\n",
      "90253                Is the baby clinging to his mother?          36.0\n",
      "90254                 Why does she love to get up early?          37.0\n",
      "90255                   We all thought it was hilarious.          38.0\n",
      "10\n",
      "1\n",
      "90246     True\n",
      "90247    False\n",
      "90248    False\n",
      "90249    False\n",
      "90250    False\n",
      "90251    False\n",
      "90252    False\n",
      "90253    False\n",
      "90254    False\n",
      "90255    False\n",
      "Name: steps.prompt, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_df = crowd_df[crowd_df['steps.participantId']==participant_ids[0]][['steps.prompt', 'steps.stepId']]\n",
    "print(prompt_df)\n",
    "print(len(prompt_df))\n",
    "# if len(prompt_df==0):\n",
    "    # return -1\n",
    "inds = prompt_df['steps.prompt'].str.contains('supermarket')\n",
    "print(sum(inds))\n",
    "print(inds)\n",
    "# if len(inds)==0:\n",
    "    # return -1\n",
    "# else:\n",
    "int(prompt_df[inds]['steps.stepId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c74a71de-66c0-4d7a-b923-a7c13c6f95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stepid_from_prompt(dataframe, participant_id, prompt):\n",
    "    prompt_df = dataframe[dataframe['steps.participantId']==participant_id][['steps.prompt', 'steps.stepId']]\n",
    "    if len(prompt_df)==0:\n",
    "        return -1\n",
    "    inds = prompt_df['steps.prompt'].str.contains(prompt)\n",
    "    if len(inds)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return int(prompt_df[inds]['steps.stepId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0acb4d94-439f-4305-9e3a-979f0b8de21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/prad.kadambi/anaconda3/envs/pykaldi/lib/python3.7/site-packages/transformers/configuration_utils.py:354: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
     ]
    }
   ],
   "source": [
    "from gop_helper_fns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "464fbbaf-2246-43db-973d-f532b19bd3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from src.Charsiu import charsiu_forced_aligner\n",
    "from alignment_helper_fns import *\n",
    "charsiu = charsiu_forced_aligner('charsiu/en_w2v2_fc_10ms')\n",
    "alignment_dir = './crowd_alignments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be3b1e43-1795-45a8-8ebc-40071f94786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [17:59,  4.67s/it]\n"
     ]
    }
   ],
   "source": [
    "participantids = dnncrowd['File_id']\n",
    "BUCKET = 'a2services-prod-sessionartifacts-crowdsource'\n",
    "df_partids = np.array(list(crowd_df['session.participantId']))\n",
    "artps_array = np.zeros([len(df_partids), 5])\n",
    "steps = stepid_to_transcript.keys()\n",
    "results_dict = './crowd_validation_artps_fixed.pkl'\n",
    "if not os.path.exists(results_dict):\n",
    "    session_artp_validation_dict = {}\n",
    "    for ii, pid in tqdm.tqdm(enumerate(participantids)):\n",
    "        session_artp_validation_dict[pid] = {}\n",
    "        inds = np.argwhere(df_partids==pid).ravel()\n",
    "        _sessid = crowd_df.iloc[inds]['session.sessionId'].iloc[0]\n",
    "        _sessidz = int(_sessid)\n",
    "        for jj, _prompt_substr in enumerate(prompt_substrings): \n",
    "            step = get_stepid_from_prompt(crowd_df, pid, _prompt_substr)\n",
    "            _transcript = substr_to_transcript[_prompt_substr]\n",
    "            _step_audiopath = '/'.join([pid, '%d/%d.wav' % (_sessid, step)])\n",
    "            # audio = Audio.from_wav_s3_bucket(bucket = BUCKET,\n",
    "                                             # object_key = _step_audiopath)\n",
    "            try:\n",
    "                audio_signal = s3_to_npscale(BUCKET, _step_audiopath)\n",
    "                # len(audio_signal)\n",
    "                # break\n",
    "                #do alignment\n",
    "                # output_tg_dir = os.path.join(alignment_dir, pid, _sessid + '-' + str(step)+'.TextGrid')\n",
    "                # charsiu.serve()\n",
    "                #calculate artp\n",
    "                mean_gop, phonewise_gop = calculate_GOP_e2e(audio=audio_signal, transcript=_transcript)\n",
    "                session_artp_validation_dict[pid][step] = mean_gop\n",
    "                artps_array[ii, jj] = mean_gop\n",
    "                # print(mean_gop)\n",
    "            except:\n",
    "                session_artp_validation_dict[pid][step] = np.nan\n",
    "                artps_array[ii, jj] = np.nan\n",
    "                \n",
    "            # break\n",
    "        # break\n",
    "import pickle as pkl\n",
    "pkl.dump(session_artp_validation_dict, open(results_dict, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04d382-851a-497d-98e2-99ad1b5e47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nan = 0\n",
    "for pid in tqdm.tqdm(participant_ids):\n",
    "    session_artp_validation_dict[pid] = {}\n",
    "    inds = np.argwhere(df_partids==pid).ravel()\n",
    "    _sessid = crowd_df.iloc[inds]['session.sessionId'].iloc[0]\n",
    "    _sessidz = int(_sessid)\n",
    "    for step in steps:     \n",
    "        _transcript = stepid_to_transcript[step]\n",
    "        _step_audiopath = '/'.join([pid, '%d/%d.wav' % (_sessid, step)])\n",
    "        # audio = Audio.from_wav_s3_bucket(bucket = BUCKET,\n",
    "                                         # object_key = _step_audiopath)\n",
    "        try:\n",
    "            audio_signal = s3_to_npscale(BUCKET, _step_audiopath)\n",
    "        except:\n",
    "            n_nan+=1\n",
    "# print(n_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e7bb91-09ca-4fb7-8351-786f7b292aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8c904-613b-457f-bb25-cf7be63733f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c736b1-ac17-4a12-bf5b-6df57ecab5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e81acb2d-4cf9-47a8-a12a-f2ef030970a0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_df['steps.participantId'][0]\n",
    "# crowd_df['steps.partitionId'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a8631d-4708-4df5-853e-8a82614232a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnndf['']\n",
    "bucket = crowd_df['steps.s3Bucket'][0]\n",
    "sessid = crowd_df['steps.sessionId'][0]\n",
    "objkey = crowd_df['steps.participantId'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160d6b8-9b4f-4cd3-aeba-d423ff865ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio.from_wav_s3_bucket(bucket=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426fd1e-a072-47b1-815e-577d41fb96cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "alignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
