{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a490935-7230-4e3f-bcde-7ff60d07276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics_core.audio import Audio\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e8ae3e-6a3d-4eda-b07e-bf351c91ea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prad.kadambi/anaconda3/envs/pykaldi/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (5,50,51,52,53,54,55,56,57,58,59,60,62,63,64,65,66,67,68,69,73,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,150,151,152,153,154,155,156,157,169,170,171,172,173,174,335,336,338,339,340,341,342,343,344,345,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,371,372,373,374,375,376,377,378,379,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,450,451,452,453,454,455,456,457,458,459,460,461,462,463,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,486,579) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/dataset_files/crowd-source__asr_2021-11-08__final__ALL.csv')\n",
    "dnndf = pd.read_csv('./data/dataset_files/DNN.csv')\n",
    "crowd_df = df[df['steps.stepCategory']=='sentence']\n",
    "dnncrowd = dnndf[dnndf['sample'].isin(['crowd', 'crowd_issue'])]\n",
    "dnnids = list(dnncrowd['File_id'])\n",
    "crowd_df = crowd_df[crowd_df['steps.participantId'].isin(dnnids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96489fec-7e90-4fdf-9c2e-9ce00c391c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_to_npscale(bucket, obj_key):\n",
    "    data = Audio.from_wav_s3_bucket(bucket=bucket, object_key=obj_key)\n",
    "    return data.audio_signal / (2 ** 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ce19d1-3408-4adc-9a71-888ea9639469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session.appDevice', 'session.appName', 'session.appPlatform',\n",
       "       'session.appVersion', 'session.createdTime', 'session.inClinic',\n",
       "       'session.language', 'session.microphone', 'session.participantId',\n",
       "       'session.partitionId', 'session.sessionCount', 'session.sessionId',\n",
       "       'session.sessionScriptId', 'session.sortId', 'session.startTime',\n",
       "       'session.totalSteps', 'session.type', 'session.uuid',\n",
       "       'steps.partitionId', 'steps.sortId', 'steps.type',\n",
       "       'steps.participantId', 'steps.sessionId', 'steps.stepId',\n",
       "       'steps.createdTime', 'steps.s3Bucket', 'steps.s3Path',\n",
       "       'steps.elicitType', 'steps.microphone', 'steps.stepCategory',\n",
       "       'steps.startTime', 'steps.endTime', 'steps.status', 'steps.name',\n",
       "       'steps.sequenceNumber', 'steps.rating', 'steps.singleSelect',\n",
       "       'steps.uuid', 'steps.promptListSize', 'steps.promptType',\n",
       "       'steps.prompt', 'steps.originalSampleRate', 'steps.stepData',\n",
       "       'transcript.simple.human', 'transcript.raw.human',\n",
       "       'transcript.createdTime.human', 'transcript.stepId',\n",
       "       'transcript.raw.aws', 'transcript.simple.aws',\n",
       "       'transcript.createdTime.aws'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_df.columns[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6c3508-651f-45a5-af5c-dd2ec155704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepid_to_transcript = \\\n",
    "{37: 'The supermarket chain shut down because of poor management', \n",
    "38: 'Much more money must be donated to make this department succeed', \n",
    "39: 'In this famous coffee shop they serve the best donuts in town',\n",
    "40: 'The chairman decided to pave over the shopping center garden', \n",
    "41: 'The standards committee met this afternoon in an open meeting'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25bb5a1-6690-4f93-a4a9-2043857f4877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 43)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnncrowd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574a3569-a922-49d2-b949-a5f10cf5142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num multiple sess:\t 0\n",
      "corrects:\t 231\n",
      "notfounds:\t 0\n"
     ]
    }
   ],
   "source": [
    "'''just checking that theres only one session per participant id'''\n",
    "correct =  0\n",
    "notfounds = 0\n",
    "nmultimplesess = 0\n",
    "# participant_ids = crowd_df['session.participantId']\n",
    "participant_ids = list(dnncrowd['File_id'])\n",
    "df_partids = np.array(list(crowd_df['session.participantId']))\n",
    "for pid in participant_ids:\n",
    "    inds = np.argwhere(df_partids == pid).ravel()\n",
    "    sids = np.unique(crowd_df.iloc[inds]['session.sessionId'])\n",
    "    if len(sids)>1:\n",
    "        print(sess)\n",
    "        nmultimplesess += 1\n",
    "    elif len(sids)==1:\n",
    "        # print('correct')\n",
    "        correct += 1\n",
    "    else:\n",
    "        # print('not found')\n",
    "        notfounds+= 1\n",
    "print('num multiple sess:\\t', nmultimplesess)\n",
    "print('corrects:\\t', correct)\n",
    "print('notfounds:\\t', notfounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "868e0675-01c4-43a2-8bba-a1f8bfb5b294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1615491157612.0\n"
     ]
    }
   ],
   "source": [
    "pid = df_partids[0]\n",
    "inds = np.argwhere(df_partids==pid).ravel()\n",
    "sess = crowd_df.iloc[inds]['session.sessionId'].iloc[0]\n",
    "print(sess)\n",
    "# print(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc0d9e4-1eb1-45f4-ad7e-77538207a939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess in list(crowd_df['session.participantId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0acb4d94-439f-4305-9e3a-979f0b8de21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/prad.kadambi/anaconda3/envs/pykaldi/lib/python3.7/site-packages/transformers/configuration_utils.py:354: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
     ]
    }
   ],
   "source": [
    "from gop_helper_fns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464fbbaf-2246-43db-973d-f532b19bd3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from src.Charsiu import charsiu_forced_aligner\n",
    "from alignment_helper_fns import *\n",
    "charsiu = charsiu_forced_aligner('charsiu/en_w2v2_fc_10ms')\n",
    "alignment_dir = './crowd_alignments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34e78f7c-c462-4508-8bd0-cbc14ee31f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/231 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'session_artp_validation_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26277/2457486587.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_nan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipant_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msession_artp_validation_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_partids\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_sessid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrowd_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session.sessionId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'session_artp_validation_dict' is not defined"
     ]
    }
   ],
   "source": [
    "n_nan = 0\n",
    "for pid in tqdm.tqdm(participant_ids):\n",
    "    session_artp_validation_dict[pid] = {}\n",
    "    inds = np.argwhere(df_partids==pid).ravel()\n",
    "    _sessid = crowd_df.iloc[inds]['session.sessionId'].iloc[0]\n",
    "    _sessidz = int(_sessid)\n",
    "    for step in steps:     \n",
    "        _transcript = stepid_to_transcript[step]\n",
    "        _step_audiopath = '/'.join([pid, '%d/%d.wav' % (_sessid, step)])\n",
    "        # audio = Audio.from_wav_s3_bucket(bucket = BUCKET,\n",
    "                                         # object_key = _step_audiopath)\n",
    "        try:\n",
    "            audio_signal = s3_to_npscale(BUCKET, _step_audiopath)\n",
    "        except:\n",
    "            n_nan+=1\n",
    "# print(n_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be3b1e43-1795-45a8-8ebc-40071f94786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [19:42,  5.12s/it]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30426/690300899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_artp_validation_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_results_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pkl'"
     ]
    }
   ],
   "source": [
    "participantids = dnncrowd['File_id']\n",
    "BUCKET = 'a2services-prod-sessionartifacts-crowdsource'\n",
    "df_partids = np.array(list(crowd_df['session.participantId']))\n",
    "artps_array = np.zeros([len(df_partids), 5])\n",
    "steps = stepid_to_transcript.keys()\n",
    "results_dict = './crowd_validation_artps_fixed.pkl'\n",
    "if not os.path.exists(results_dict):\n",
    "    session_artp_validation_dict = {}\n",
    "    for ii, pid in tqdm.tqdm(enumerate(participantids)):\n",
    "        session_artp_validation_dict[pid] = {}\n",
    "        inds = np.argwhere(df_partids==pid).ravel()\n",
    "        _sessid = crowd_df.iloc[inds]['session.sessionId'].iloc[0]\n",
    "        _sessidz = int(_sessid)\n",
    "        for jj, step in enumerate(steps):     \n",
    "            _transcript = stepid_to_transcript[step]\n",
    "            _step_audiopath = '/'.join([pid, '%d/%d.wav' % (_sessid, step)])\n",
    "            # audio = Audio.from_wav_s3_bucket(bucket = BUCKET,\n",
    "                                             # object_key = _step_audiopath)\n",
    "            try:\n",
    "                audio_signal = s3_to_npscale(BUCKET, _step_audiopath)\n",
    "                # len(audio_signal)\n",
    "                # break\n",
    "                #do alignment\n",
    "                # output_tg_dir = os.path.join(alignment_dir, pid, _sessid + '-' + str(step)+'.TextGrid')\n",
    "                # charsiu.serve()\n",
    "                #calculate artp\n",
    "                mean_gop, phonewise_gop = calculate_GOP_e2e(audio=audio_signal, transcript=_transcript)\n",
    "                session_artp_validation_dict[pid][step] = mean_gop\n",
    "                artps_array[ii, jj] = mean_gop\n",
    "                # print(mean_gop)\n",
    "            except:\n",
    "                session_artp_validation_dict[pid][step] = np.nan\n",
    "                artps_array[ii, jj] = np.nan\n",
    "                \n",
    "            # break\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e7bb91-09ca-4fb7-8351-786f7b292aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(session_artp_validation_dict, open(results_dict, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8c904-613b-457f-bb25-cf7be63733f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c736b1-ac17-4a12-bf5b-6df57ecab5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e81acb2d-4cf9-47a8-a12a-f2ef030970a0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_df['steps.participantId'][0]\n",
    "# crowd_df['steps.partitionId'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a8631d-4708-4df5-853e-8a82614232a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnndf['']\n",
    "bucket = crowd_df['steps.s3Bucket'][0]\n",
    "sessid = crowd_df['steps.sessionId'][0]\n",
    "objkey = crowd_df['steps.participantId'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160d6b8-9b4f-4cd3-aeba-d423ff865ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio.from_wav_s3_bucket(bucket=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426fd1e-a072-47b1-815e-577d41fb96cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykaldi",
   "language": "python",
   "name": "pykaldi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
