{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6c4363-31ea-498a-88f1-1c36ee0ff20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prad/anaconda3/envs/a2/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/prad/anaconda3/envs/a2/lib/python3.7/site-packages/transformers/configuration_utils.py:359: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "/home/prad/anaconda3/envs/a2/lib/python3.7/site-packages/Bio/pairwise2.py:283: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  BiopythonDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from alignment_helper_fns import *\n",
    "from gop_helper_fns import *\n",
    "from mfa_evaluation_utils import *\n",
    "from g2p_en import G2p\n",
    "g2p = G2p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d52e57-a335-4114-91ab-5fea9f697afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "satdf = pd.read_csv('./results_sat/results.csv').set_index('Unnamed: 0')\n",
    "xsatdf = pd.read_csv('./results_sat_xvector/results_xvector_proj.csv')\n",
    "xsatdf = xsatdf.rename(columns={'Unnamed: 0': 'Speaker'})\n",
    "\n",
    "ALL_SPEAKERS = list(satdf.index)\n",
    "\n",
    "results_dir_frame = './results_frame_10epochs'\n",
    "results_dir_ivec = './results_sat'\n",
    "# results_dir_xvec = './results_sat_xvector'\n",
    "results_dir_xvec = './phone_matched_xvec_proj_textgrids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a209964-fbf1-4df7-9c03-980295cda2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all textgrids in directory:\t /home/prad/datasets/ChildSpeechDataset/manually-aligned-text-grids/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:00, 6417.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all textgrids in directory:\t ./results_sat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:00, 6064.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all textgrids in directory:\t ./phone_matched_xvec_proj_textgrids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:00, 6296.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all textgrids in directory:\t ./results_mfa_adapted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Mismatched:\t 0\n",
      "3762\n",
      "3762\n",
      "3762\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EXCLUDE_FILES = ['0505_M_EKs4T10', '0411_M_LMwT32']\n",
    "\n",
    "allmanual_tgs = [pth for pth in get_all_textgrids_in_directory('/home/prad/datasets/ChildSpeechDataset/manually-aligned-text-grids/') if '.TextGrid' in pth]\n",
    "allmanual_tgs = [tg for tg in allmanual_tgs if all([_excludefile not in tg for _excludefile in EXCLUDE_FILES])]\n",
    "\n",
    "ivector_tgs =[pth for pth in get_all_textgrids_in_directory('./results_sat') if '.TextGrid' in pth]\n",
    "ivector_tgs = [tg for tg in ivector_tgs if all([_excludefile not in tg for _excludefile in EXCLUDE_FILES])]\n",
    "\n",
    "\n",
    "xvector_tgs =[pth for pth in get_all_textgrids_in_directory('./phone_matched_xvec_proj_textgrids') if '.TextGrid' in pth]\n",
    "# xvector_tgs =[pth for pth in get_all_textgrids_in_directory('./results_xvector_reevaluated') if '.TextGrid' in pth]\n",
    "xvector_tgs = [tg for tg in xvector_tgs if all([_excludefile not in tg for _excludefile in EXCLUDE_FILES])]\n",
    "\n",
    "mfa_tgs = [pth for pth in get_all_textgrids_in_directory('./results_mfa_adapted') if '.TextGrid' in pth]\n",
    "mfa_tgs = [tg for tg in mfa_tgs if all([_excludefile not in tg for _excludefile in EXCLUDE_FILES])]\n",
    "\n",
    "print('Num Mismatched:\\t', sum([f1.split('/')[-1].split('.')[0]!=f2.split('/')[-1].split('.')[0] for f1, f2 in zip(allmanual_tgs, xvector_tgs)]))\n",
    "\n",
    "print(len(allmanual_tgs))\n",
    "print(len(ivector_tgs))\n",
    "print(len(xvector_tgs))\n",
    "print(len(mfa_tgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "034d0e94-23f0-48a9-a424-a395a6758aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_to_dir = {\n",
    "                 # 'mfa_adapt_from_trained':'./results_mfa_adapted_from_trained_sat3', \n",
    "                 # 'mfa_adapt_us_arpa':'./results_mfa_adapted_english_us_arpa',\n",
    "                 # 'mfa_adapt':'./results_mfa_adapted', \n",
    "                 # 'mfa_train':'./results_mfa_train',\n",
    "                 # 'mfa_trained_old': './results_mfa_trained',\n",
    "                 # 'mfa_base': './results_mfa_base',\n",
    "                 # 'ivector': './results_sat', \n",
    "                 # 'xvector': './phone_matched_xvec_proj_textgrids', \n",
    "                 'xvectorv2': './results_sat_xvector',\n",
    "                 # 'frame': './results_frame_10epochs', \n",
    "                 'gt': '/home/prad/datasets/ChildSpeechDataset/manually-aligned-text-grids/'}\n",
    "\n",
    "methodnames = list(method_to_dir.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9be90e5b-3b93-4cb7-9706-e6a9b2f541d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alignment_accuracy_between_textgrids(manual_textgridpath: str, aligner_textgridpath: str, manual_phonekey: str,\n",
    "                                              aligner_phonekey: str, collapse_shortphones: bool, remove_numbers=True, ignore_extras=True,\n",
    "                                              ignore_silence=False, ):\n",
    "    #TODO: return the label along with whether it was correct so that you can figure out which phonemes were wrong\n",
    "\n",
    "    manualdf = textgridpath_to_phonedf(manual_textgridpath, phone_key=manual_phonekey, remove_numbers=True)\n",
    "    alignerdf = textgridpath_to_phonedf(aligner_textgridpath, phone_key=aligner_phonekey, remove_numbers=True,\n",
    "                                        replace_silence=ignore_silence)\n",
    "\n",
    "    transcript = get_transcript_from_tgfile(aligner_textgridpath)\n",
    "    if collapse_shortphones:\n",
    "        alignerdf = process_silences(alignerdf, transcript)\n",
    "\n",
    "    phn_midpoints_dict = extract_phn_midpoint_dict_from_df(manualdf)\n",
    "    correct_indicator = calc_accuracy(predphn_df=alignerdf, annotated_midpoints_dict=phn_midpoints_dict,\n",
    "                                      ignore_extras=ignore_extras)\n",
    "    #     if any([c==-1 for c in correct_indicator]):\n",
    "    if type(correct_indicator) == int:\n",
    "        print('---------------------------------------')\n",
    "        print('**********Manual************\\n', manualdf)\n",
    "        print('**********Aligned***********\\n', alignerdf)\n",
    "    return correct_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a4b9e88-3940-4261-86da-31d85731be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contains_same_phones(phone_list1, phone_list2):\n",
    "    '''\n",
    "        simply checks that two phoneme lists are the same\n",
    "        for example that a ground truth textgrid and an estimated textgrid have the same list of phonemes\n",
    "    '''\n",
    "    try:\n",
    "        # return np.logical_and.reduce(np.unique(phone_list1)==np.unique(phone_list2))    \n",
    "        return np.all(np.array(phone_list1)==np.array(phone_list2))\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def calc_acc_between_tg_lists(manual_tg_list, estimated_tg_list, collapse_shortphones: bool,  manual_phonekey='ha phones', aligner_phonekey='phones', \n",
    "                             ignore_numbers=True, ignore_extras=True, ignore_silence=False, verbose=True):\n",
    "    \n",
    "    \n",
    "    correct_indicator = []\n",
    "    correct_indicator_matched = []\n",
    "    matched_indicator = []\n",
    "    for ii, (manual_textgridpath, estimated_textgridpath) in tqdm.tqdm(enumerate(zip(manual_tg_list, estimated_tg_list))):\n",
    "        # try:\n",
    "        _correct_indicator = calc_alignment_accuracy_between_textgrids(manual_textgridpath = manual_textgridpath,\n",
    "                                                                      aligner_textgridpath = estimated_textgridpath,\n",
    "                                                                      manual_phonekey=manual_phonekey, \n",
    "                                                                      aligner_phonekey=aligner_phonekey, \n",
    "                                                                      ignore_extras=ignore_extras, \n",
    "                                                                      ignore_silence=ignore_silence, \n",
    "                                                                      collapse_shortphones=False)\n",
    "\n",
    "        correct_indicator.append(_correct_indicator)\n",
    "\n",
    "\n",
    "        manualdf = textgridpath_to_phonedf(manual_textgridpath, phone_key=manual_phonekey, remove_numbers=True)\n",
    "        alignerdf = textgridpath_to_phonedf(estimated_textgridpath, phone_key=aligner_phonekey, remove_numbers=True,\n",
    "                                    replace_silence=True)\n",
    "        transcript = get_transcript_from_tgfile(estimated_textgridpath)\n",
    "\n",
    "        manual_phones = np.array(remove_sil_from_phonelist(manualdf.phone.values))\n",
    "        aligner_phones = np.array(remove_sil_from_phonelist(alignerdf.phone.values))\n",
    "        ismatch = contains_same_phones(manual_phones, aligner_phones)\n",
    "        matched_indicator.append(ismatch)\n",
    "\n",
    "        if ismatch:\n",
    "            correct_indicator_matched.append(_correct_indicator)\n",
    "            \n",
    "        # if ii>25:\n",
    "            # break\n",
    "        # print(manualdf)\n",
    "        # print(alignerdf)\n",
    "        # print(correct_indicator)\n",
    "        # except:\n",
    "            # print('error')\n",
    "            # if not os.path.exists(estimated_textgridpath):\n",
    "                # print('Textgrid file', estimated_textgridpath, 'not found, skipping this file')\n",
    "    # print(correct_indicator)\n",
    "    \n",
    "    # return 0\n",
    "    correct_indicator = np.concatenate(correct_indicator)\n",
    "    acc = np.mean(correct_indicator)\n",
    "    numcorrect = np.sum(correct_indicator)\n",
    "    numpredicted = len(correct_indicator)\n",
    "\n",
    "    correct_indicator_matched = np.concatenate(correct_indicator_matched)    \n",
    "    acc_matched = np.mean(correct_indicator_matched)\n",
    "    numcorrect_matched = np.sum(correct_indicator_matched)\n",
    "    numpredicted_matched = len(correct_indicator_matched)\n",
    "    \n",
    "    if verbose:\n",
    "        print('============ Total Accuracy ============')\n",
    "        print('Accuracy:\\t', np.mean(correct_indicator))\n",
    "        print('Num Correct:\\t', numcorrect)\n",
    "        print('Num Predicted Phones:\\t', numpredicted)\n",
    "        print('============ Matched Accuracy ============')\n",
    "        print('Matched Accuracy:\\t', np.mean(correct_indicator_matched))\n",
    "        print('Num Correct Matched:\\t', numcorrect_matched)\n",
    "        print('Num Predicted Phones Matched:\\t', numpredicted_matched)\n",
    "    \n",
    "    return acc, acc_matched, numcorrect, numcorrect_matched, numpredicted, numpredicted_matched, matched_indicator\n",
    "    \n",
    "    \n",
    "def calculate_accuracy_for_methods(speakers, methodname, method_to_dir=method_to_dir):\n",
    "    \n",
    "    correct_indicator_matched = []\n",
    "    correct_indicator = []\n",
    "    \n",
    "    all_gt_tgs = []\n",
    "    all_method_tgs = []\n",
    "    \n",
    "    for speakerid in speakers:\n",
    "        tgs_manualpath = os.path.join(method_to_dir['gt'], speakerid)\n",
    "        tgs_methodpath = os.path.join(method_to_dir[methodname], speakerid)\n",
    "        tgs_manual = get_all_textgrids_in_directory(tgs_manualpath, verbose=False)\n",
    "        tgs_method = get_all_textgrids_in_directory(tgs_methodpath, verbose=False)\n",
    "    \n",
    "        all_gt_tgs.extend(tgs_manual)\n",
    "        all_method_tgs.extend(all_method_tgs)\n",
    "        \n",
    "    acc, acc_matched, numcorrect, numcorrect_matched, numpredicted, numpredicted_matched = \\\n",
    "        calc_acc_between_tg_lists(tgs_manual, tgs_method, collapse_shortphones=True,  manual_phonekey='ha phones', aligner_phonekey='phones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "971c9a17-2884-4ed2-a7a4-55643db4dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Methodname: xvectorv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3763it [00:19, 192.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Total Accuracy ============\n",
      "Accuracy:\t 0.5412100684067211\n",
      "Num Correct:\t 8149.0\n",
      "Num Predicted Phones:\t 15057\n",
      "============ Matched Accuracy ============\n",
      "Matched Accuracy:\t 0.9449916372421483\n",
      "Num Correct Matched:\t 5085\n",
      "Num Predicted Phones Matched:\t 5381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "speakers = ALL_SPEAKERS\n",
    "# methodname='mfa_train'\n",
    "# methodname='mfa_trained_old'\n",
    "# methodname = 'xvector'\n",
    "collapse_shortphones=False\n",
    "acc_results_dct = {}\n",
    "\n",
    "for methodname in method_to_dir.keys():\n",
    "    if methodname=='gt':\n",
    "        continue\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Methodname:', methodname)\n",
    "    correct_indicator_matched = []\n",
    "    correct_indicator = []\n",
    "\n",
    "    all_gt_tgs = []\n",
    "    all_method_tgs = []\n",
    "\n",
    "    for speakerid in speakers:\n",
    "        tgs_manualpath = os.path.join(method_to_dir['gt'], speakerid)\n",
    "        tgs_methodpath = os.path.join(method_to_dir[methodname], speakerid)\n",
    "        tgs_manual = get_all_textgrids_in_directory(tgs_manualpath, verbose=False)\n",
    "        tgs_method = get_all_textgrids_in_directory(tgs_methodpath, verbose=False)\n",
    "\n",
    "        all_gt_tgs.extend(tgs_manual)\n",
    "        all_method_tgs.extend(tgs_method)\n",
    "\n",
    "    acc, acc_matched, numcorrect, numcorrect_matched, numpredicted, numpredicted_matched, matched_indicator = \\\n",
    "        calc_acc_between_tg_lists(all_gt_tgs, all_method_tgs, collapse_shortphones=collapse_shortphones,  manual_phonekey='ha phones', aligner_phonekey='phones')\n",
    "    acc_results_dct[methodname] = {'Acc': acc, \n",
    "                                   'NumCorrect':numcorrect, \n",
    "                                   'NumPredicted':numpredicted,\n",
    "                                   'AccMatched': acc_matched,\n",
    "                                   'NumCorrectMatched':numcorrect_matched, \n",
    "                                   'NumPredictedMatched':numpredicted_matched}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8545f5b8-3c9e-4098-b1b8-f0ae1d759fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_results_df = pd.DataFrame.from_dict(acc_results_dct).T\n",
    "acc_results_df.to_csv('./interspeech_results/acc_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c8c430-be21-41aa-8a02-072fa42535a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>NumCorrect</th>\n",
       "      <th>NumPredicted</th>\n",
       "      <th>AccMatched</th>\n",
       "      <th>NumCorrectMatched</th>\n",
       "      <th>NumPredictedMatched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mfa_adapt_from_trained</th>\n",
       "      <td>0.606486</td>\n",
       "      <td>561.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0.627483</td>\n",
       "      <td>379.0</td>\n",
       "      <td>604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfa_adapt_us_arpa</th>\n",
       "      <td>0.721616</td>\n",
       "      <td>661.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>0.719611</td>\n",
       "      <td>444.0</td>\n",
       "      <td>617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfa_train</th>\n",
       "      <td>0.606486</td>\n",
       "      <td>561.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0.627483</td>\n",
       "      <td>379.0</td>\n",
       "      <td>604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfa_trained_old</th>\n",
       "      <td>0.878289</td>\n",
       "      <td>801.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>0.906937</td>\n",
       "      <td>536.0</td>\n",
       "      <td>591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfa_base</th>\n",
       "      <td>0.710383</td>\n",
       "      <td>650.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.706645</td>\n",
       "      <td>436.0</td>\n",
       "      <td>617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ivector</th>\n",
       "      <td>0.918542</td>\n",
       "      <td>857.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>522.0</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xvector</th>\n",
       "      <td>0.928799</td>\n",
       "      <td>874.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>0.935867</td>\n",
       "      <td>788.0</td>\n",
       "      <td>842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame</th>\n",
       "      <td>0.901499</td>\n",
       "      <td>842.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>0.928437</td>\n",
       "      <td>493.0</td>\n",
       "      <td>531.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Acc  NumCorrect  NumPredicted  AccMatched  \\\n",
       "mfa_adapt_from_trained  0.606486       561.0         925.0    0.627483   \n",
       "mfa_adapt_us_arpa       0.721616       661.0         916.0    0.719611   \n",
       "mfa_train               0.606486       561.0         925.0    0.627483   \n",
       "mfa_trained_old         0.878289       801.0         912.0    0.906937   \n",
       "mfa_base                0.710383       650.0         915.0    0.706645   \n",
       "ivector                 0.918542       857.0         933.0    0.947368   \n",
       "xvector                 0.928799       874.0         941.0    0.935867   \n",
       "frame                   0.901499       842.0         934.0    0.928437   \n",
       "\n",
       "                        NumCorrectMatched  NumPredictedMatched  \n",
       "mfa_adapt_from_trained              379.0                604.0  \n",
       "mfa_adapt_us_arpa                   444.0                617.0  \n",
       "mfa_train                           379.0                604.0  \n",
       "mfa_trained_old                     536.0                591.0  \n",
       "mfa_base                            436.0                617.0  \n",
       "ivector                             522.0                551.0  \n",
       "xvector                             788.0                842.0  \n",
       "frame                               493.0                531.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88cd5f1a-9c5c-4f27-a1c4-568e6bd144c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>NumCorrect</th>\n",
       "      <th>NumPredicted</th>\n",
       "      <th>AccMatched</th>\n",
       "      <th>NumCorrectMatched</th>\n",
       "      <th>NumPredictedMatched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mfa_trained_old</th>\n",
       "      <td>0.878289</td>\n",
       "      <td>801.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>0.906937</td>\n",
       "      <td>536.0</td>\n",
       "      <td>591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfa_base</th>\n",
       "      <td>0.710383</td>\n",
       "      <td>650.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.706645</td>\n",
       "      <td>436.0</td>\n",
       "      <td>617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ivector</th>\n",
       "      <td>0.918542</td>\n",
       "      <td>857.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>522.0</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xvector</th>\n",
       "      <td>0.928799</td>\n",
       "      <td>874.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>0.935867</td>\n",
       "      <td>788.0</td>\n",
       "      <td>842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame</th>\n",
       "      <td>0.901499</td>\n",
       "      <td>842.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>0.928437</td>\n",
       "      <td>493.0</td>\n",
       "      <td>531.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Acc  NumCorrect  NumPredicted  AccMatched  \\\n",
       "mfa_trained_old  0.878289       801.0         912.0    0.906937   \n",
       "mfa_base         0.710383       650.0         915.0    0.706645   \n",
       "ivector          0.918542       857.0         933.0    0.947368   \n",
       "xvector          0.928799       874.0         941.0    0.935867   \n",
       "frame            0.901499       842.0         934.0    0.928437   \n",
       "\n",
       "                 NumCorrectMatched  NumPredictedMatched  \n",
       "mfa_trained_old              536.0                591.0  \n",
       "mfa_base                     436.0                617.0  \n",
       "ivector                      522.0                551.0  \n",
       "xvector                      788.0                842.0  \n",
       "frame                        493.0                531.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_indices = ['mfa_train', 'mfa_adapt_from_trained', 'mfa_adapt_us_arpa'] \n",
    "acc_results_df.drop(remove_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135146d-dd44-40bb-94d0-bbb5c2bbd041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81ba96-3dd9-40f0-a457-ed9a13f99025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfd037-9361-4baa-a4b4-ff31c44e153e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa5f558-cf32-459a-b160-d3d9678691b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a2",
   "language": "python",
   "name": "a2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
